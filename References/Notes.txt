#Jenny Smith
#November 5, 2019
#Odds and Ends



#Defining tuples requires TWO different declarations of file(). Must use .map() function as well.
#The first file() is when the filename is read in from the sample sheet.
#Then it needs to be declared a second time under `input: tuple val(Sample), file(R1), file(R2) from fqs_ch`

#Example DOES NOT WORK!
fqs_ch = Channel.fromPath(file(params.sample_sheet)).splitCsv(header: true, sep: '\t')
fqs_ch.subscribe{ println "${it}\n" }
[Sample:PANISJ-09A-01R, R1:s3://fh-pi-meshinchi-s/SR/picard_fq2/PANISJ-09A-01R_withJunctionsOnGenome_dupsFlagged_r1.fq.gz, R2:s3://fh-pi-meshinchi-s/SR/picard_fq2/PANISJ-09A-01R_withJunctionsOnGenome_dupsFlagged_r2.fq.gz]
[Sample:PANMTU-09A-01R, R1:s3://fh-pi-meshinchi-s/SR/picard_fq2/PANMTU-09A-01R_withJunctionsOnGenome_dupsFlagged_r1.fq.gz, R2:s3://fh-pi-meshinchi-s/SR/picard_fq2/PANMTU-09A-01R_withJunctionsOnGenome_dupsFlagged_r2.fq.gz]

#Example DOES WORK
fqs_ch = Channel.fromPath(file(params.sample_sheet))
						.splitCsv(header: true, sep: '\t')
						.map { sample -> [sample["Sample"], file(sample["R1"]), file(sample["R2"])]}
fqs_ch.subscribe{ println "${it}\n" }


#interactive STAR-fusion container run
#optionally add a volume to connect local data for testing with -v $(PWD):/data
docker run -ti --rm  --entrypoint /bin/bash trinityctat/starfusion:1.8.1

#how NF downloads files...
nxf_s3_download() {
    local source=$1
    local target=$2
    local file_name=$(basename $1)
    local is_dir=$(/home/ec2-user/miniconda/bin/aws --region us-west-2 s3 ls $source | grep -F "PRE ${file_name}/" -c)
    if [[ $is_dir == 1 ]]; then
        /home/ec2-user/miniconda/bin/aws --region us-west-2 s3 cp --only-show-errors --recursive "$source" "$target"
    else
        /home/ec2-user/miniconda/bin/aws --region us-west-2 s3 cp --only-show-errors "$source" "$target"
    fi
}


#For a recursive ls with limited depth in bash
find . -maxdepth 3 -type d -ls

#Useful for parsing S3 working(temporary) directory
#From Sam Minot
aws s3 ls --recursive s3://fh-pi-meshinchi-s/SR/work/ | grep .command.err | sort | grep 2019-11-14 | sed 's/.* //' | while read url; do aws s3 cp s3://fh-pi-meshinchi-s/$url - ; sleep 1; done
aws s3 ls --recursive s3://fh-pi-meshinchi-s/SR/work/ | grep .command.sh | sort | grep 2019-11-14 | sed 's/.* //' | while read url; do aws s3 cp s3://fh-pi-meshinchi-s/$url - ; sleep 1; done


export CTAT_GENOME_LIB=\$PWD/$genome_lib
--FusionInspector inspect or validate
